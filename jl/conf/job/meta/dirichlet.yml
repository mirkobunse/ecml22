#
# conf/meta/dirichlet.yml
#
# Meta-configuration for comparing methods on telescope data
# with multiple sampling protocols. Namely, APP and NPP are
# implemented through a Dirichlet prior.
#
job: dirichlet # this file configures the function Job.<job>
seed: 876 # random number generator seed
N_trn: 20000 # number of training data items
M_val: 1000 # number of validation samples
M_tst: 5000 # number of testing samples
N_val: 1000 # number of items in each validation sample
N_tst: 1000 # number of items in each testing sample


# output of configuration expansion and of experiments
configfile: conf/job/gen/dirichlet_$(dataset).yml
outfile: res/metrics/dirichlet_$(dataset).csv
valfile: res/metrics/dirichlet_val_$(dataset).csv


# all data sets to be used
dataset:
  - fact # FACT telescope data

  # UCI data sets
  - blog-feedback
  - online-news-popularity

  # OpenML data sets
  - Yolanda
  - fried
  - Airlines_DepDelay_1M

# the sampling protocols with which to evaluate
protocol:
  sampling: app # app or npp
  n_splits: 5 # investigate multiple levels of curvature + all data


# all classifiers over which the quantification methods are optimized
classifier:

  - name: "DT ($w=$(class_weight), c=$(criterion), d=$(max_depth)$)"
    classifier: DecisionTreeClassifier
    calibration: isotonic
    package: tree
    parameters:
      criterion: [ "entropy", "gini" ]
      max_depth: [ 4, 6, 8, 10, 12 ]
      class_weight: [ "balanced", ~ ]
      max_features: sqrt
      random_state: 876

  - classifier: LogisticRegression # not tried on FACT (does not work, anyway)
    method_id: logReg
    name: "LR ($w=$(class_weight), C=$(C)$)"
    parameters:
      C: [ 0.001, 0.01, 0.1, 1.0, 10.0 ]
      class_weight: [ "balanced", ~ ]

# all methods to be compared
method:

  # Iterative Bayesian Unfolding without smoothing
  - method_id: ibu
    epsilon: 1e-6
    K: 1000
    binning:
      method_id: tree
      J: [ 60, 120, 180 ] # 5, 10, and 15 times the number of classes (12)
    smoothing:
      method_id: "polynomial"
      order: [ 0, 1, 2 ]
      impact: [ .1, .01, 0.0 ]
      avg_negative: false
      warn: false
    stepsize:
      method_id: constant
      alpha: 1.0
    name: "IBU ($o=$(order), i=$(impact), J=$(J)$)"

  # p-RUN: positive-constrained maximum likelihood estimate
  - method_id: prun
    epsilon: 1e-6
    warn: false
    K: 1000
    binning:
      method_id: tree
      J: [ 60, 120, 180 ]
    ac_regularisation: false
    tau: [ 1e-1, 1e-3, 1e-5 ]
    name: "RUN ($\\tau=$(tau), J=$(J)$)"

  # Ordinal Quantification Tree (CAUTION: will break with costly ensemble skconfigs)
  - method_id: oqt
    name: "OQT ($v=$(val_split)$) on $(classifier)"
    epsilon: 1e-6
    val_split: [ 0.334 ] # 1/3

  - method_id: "arc" # AdjustedRegressAndCount (by Andrea Esuli)
    name: "ARC ($v=$(val_split)$) on $(classifier)"
    val_split: [ 0.334 ]

  # Classify and Count variants from QuaPy.jl
  - method_id: cc # ClassifyAndCount
    name: "CC on $(classifier)"

  - method_id: pcc # ProbabilisticClassifyAndCount
    name: "PCC on $(classifier)"

  - method_id: acc # AdjustedClassifyAndCount
    name: "ACC ($v=$(val_split)$) on $(classifier)"
    val_split: [ 0.25, 0.334, 0.5 ] # 1/4, 1/3 and 1/2

  - method_id: pacc # ProbabilisticAdjustedClassifyAndCount
    name: "PACC ($v=$(val_split)$) on $(classifier)"
    val_split: [ 0.25, 0.334, 0.5 ]

  - method_id: emq # ExpectationMaximizationQuantifier
    name: "EMQ on $(classifier)"

  - method_id: semq # our smooth version of EMQ
    name: "s-EMQ ($o=$(order), i=$(impact)$) on $(classifier)"
    smoothing:
      method_id: "polynomial"
      order: [ 0, 1, 2 ]
      impact: [ 1e-1, 3e-2, 1e-2 ]
      avg_negative: false
      warn: false

  - method_id: nacc # our smooth version of ACC
    name: "NACC ($r=$(regularization), \\tau=$(tau), v=$(val_split)$) on $(classifier)"
    val_split: [ 0.334 ]
    criterion: [ "mse" ]
    regularization: [ "curvature", "norm" ]
    tau: [ 1e-1, 1e-3, 1e-5 ]

  - method_id: npacc # our smooth version of PACC
    name: "NPACC ($r=$(regularization), \\tau=$(tau), v=$(val_split)$) on $(classifier)"
    val_split: [ 0.334 ]
    criterion: [ "mse" ]
    regularization: [ "curvature", "norm" ]
    tau: [ 1e-1, 1e-3, 1e-5 ]
